[project]
name = "ml-inference-api"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "fastapi>=0.120.0",
    "httpx>=0.28.1",
    "ipykernel>=7.0.1",
    "locust>=2.42.0",
    "numpy>=2.3.4",
    "prometheus-client>=0.23.1",
    "prometheus-fastapi-instrumentator>=7.1.0",
    "python-dotenv>=1.1.1",
    "redis>=7.0.1",
    "structlog>=25.4.0",
    "transformers>=4.57.1",
    "uvicorn>=0.38.0",
]

[project.optional-dependencies]
cpu = ["torch==2.8"]
cu128 = ["torch==2.8"]

[tool.uv]
conflicts = [
  [{ extra = "cpu" }, { extra = "cu128" }]
]

[tool.uv.sources]
torch = [
  { index = "pytorch-cpu", extra = "cpu" },
  { index = "pytorch-cu128", extra = "cu128" },
]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]
include = ["benchmarks*", "inference*", "gateway*"]

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"
